{
 "metadata": {
  "name": "",
  "signature": "sha256:c2666ccc15cb4592e6af7ea92f45892cea59d2cc992a65b2eccf82a503f38af3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Import NLTK\n",
      "import nltk\n",
      "\n",
      "# Import Pandas\n",
      "import pandas as pd\n",
      "\n",
      "# Import Regular Expressions\n",
      "import re"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Check files in the folder\n",
      "import os\n",
      "os.listdir('.')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 2,
       "text": [
        "['.DS_Store',\n",
        " '.ipynb_checkpoints',\n",
        " 'Accident.txt',\n",
        " 'accident_top_250.csv',\n",
        " 'colorbrewer.min.js',\n",
        " 'd3.layout.cloud.js',\n",
        " 'en_stopwords.txt',\n",
        " 'Example(works).html',\n",
        " 'Example_csv(works).html',\n",
        " 'indexAnk.html',\n",
        " 'test.csv',\n",
        " 'Text_Processing.ipynb']"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Open text file\n",
      "raw = open('Accident.txt', 'rU').read()\n",
      "print raw[:100]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "An Analysis of the Timing of Truck and Car Accidents in a busy Freight Corridor\n",
        "\n",
        "\n",
        "The objective of t\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Tokenize raw text\n",
      "tokens = nltk.wordpunct_tokenize(raw)\n",
      "print tokens[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['An', 'Analysis', 'of', 'the', 'Timing', 'of', 'Truck', 'and', 'Car', 'Accidents']\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Lower case words\n",
      "tokens = [w.lower() for w in tokens]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Stopwords\n",
      "stopwords = pd.read_csv('en_stopwords.txt', names = ['stopword'])\n",
      "stop = list(stopwords['stopword'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Remove stopwords\n",
      "words = [word for word in tokens if word not in stop]\n",
      "print len(words)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "7431\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Remove punctuations and numbers\n",
      "punctuation = re.compile(r'[\\[ \\] \\s -.?!,\"\\=:;()|0-9]') # punctuation and numbers to be removed\n",
      "words = [punctuation.sub(\"\", word) for word in words]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Frequency distribution of words\n",
      "fdist = nltk.FreqDist(words)\n",
      "print len(fdist.most_common())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1356\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Check 250 most common words\n",
      "fdist.most_common(250)[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "[('', 2310),\n",
        " ('truck', 80),\n",
        " ('traffic', 73),\n",
        " ('pierpass', 71),\n",
        " ('accidents', 64),\n",
        " ('peak', 59),\n",
        " ('pm', 58),\n",
        " ('emissions', 56),\n",
        " ('health', 55),\n",
        " ('data', 50)]"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "value = [{'text': word, 'size': size} for word, size in fdist.most_common(250)]\n",
      "print value"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[{'text': '', 'size': 2310}, {'text': 'truck', 'size': 80}, {'text': 'traffic', 'size': 73}, {'text': 'pierpass', 'size': 71}, {'text': 'accidents', 'size': 64}, {'text': 'peak', 'size': 59}, {'text': 'pm', 'size': 58}, {'text': 'emissions', 'size': 56}, {'text': 'health', 'size': 55}, {'text': 'data', 'size': 50}, {'text': 'trucks', 'size': 46}, {'text': 'accident', 'size': 43}, {'text': 'study', 'size': 41}, {'text': 'hours', 'size': 38}, {'text': 'impacts', 'size': 32}, {'text': 'results', 'size': 29}, {'text': 'air', 'size': 29}, {'text': 'spbp', 'size': 28}, {'text': 'port', 'size': 28}, {'text': 'area', 'size': 28}, {'text': 'freeways', 'size': 28}, {'text': 'congestion', 'size': 27}, {'text': 'day', 'size': 27}, {'text': 'ports', 'size': 27}, {'text': 'al', 'size': 26}, {'text': 'time', 'size': 26}, {'text': 'los', 'size': 25}, {'text': 'nighttime', 'size': 25}, {'text': 'percent', 'size': 25}, {'text': 'average', 'size': 24}, {'text': 'freight', 'size': 24}, {'text': 'angeles', 'size': 24}, {'text': 'vehicle', 'size': 23}, {'text': 'operations', 'size': 23}, {'text': 'pollution', 'size': 23}, {'text': 'simulation', 'size': 22}, {'text': 'information', 'size': 21}, {'text': 'california', 'size': 21}, {'text': 'probability', 'size': 21}, {'text': '\\xe2', 'size': 21}, {'text': 'based', 'size': 21}, {'text': 'no', 'size': 21}, {'text': 'car', 'size': 20}, {'text': 'complex', 'size': 20}, {'text': 'found', 'size': 20}, {'text': 'long', 'size': 20}, {'text': '\\x80\\x99', 'size': 20}, {'text': 'model', 'size': 20}, {'text': 'deliveries', 'size': 19}, {'text': 'number', 'size': 19}, {'text': 'network', 'size': 19}, {'text': 'vehicles', 'size': 19}, {'text': 'program', 'size': 18}, {'text': 'pollutant', 'size': 18}, {'text': 'distribution', 'size': 18}, {'text': 'drayage', 'size': 18}, {'text': 'night', 'size': 18}, {'text': 'freeway', 'size': 17}, {'text': 'shifting', 'size': 17}, {'text': 'total', 'size': 16}, {'text': 'costs', 'size': 16}, {'text': '/', 'size': 15}, {'text': 'exposure', 'size': 15}, {'text': 'concentrations', 'size': 15}, {'text': 'resulting', 'size': 14}, {'text': 'beach', 'size': 14}, {'text': 'vmt', 'size': 14}, {'text': 'microscopic', 'size': 14}, {'text': 'reduce', 'size': 14}, {'text': 'million', 'size': 14}, {'text': 'environmental', 'size': 14}, {'text': 'emission', 'size': 14}, {'text': 'analysis', 'size': 14}, {'text': 'table', 'size': 14}, {'text': 'daytime', 'size': 14}, {'text': 'years', 'size': 13}, {'text': 'nox', 'size': 13}, {'text': 'impact', 'size': 13}, {'text': 'conditions', 'size': 13}, {'text': 'relied', 'size': 13}, {'text': 'involved', 'size': 12}, {'text': 'studies', 'size': 12}, {'text': 'related', 'size': 12}, {'text': 'approximately', 'size': 12}, {'text': 'concentration', 'size': 12}, {'text': 'miles', 'size': 12}, {'text': 'increased', 'size': 12}, {'text': 'moves', 'size': 12}, {'text': 'distributions', 'size': 12}, {'text': 'test', 'size': 12}, {'text': 'midnight', 'size': 11}, {'text': 'increase', 'size': 11}, {'text': 'year', 'size': 11}, {'text': 'benmap', 'size': 11}, {'text': 'analyzed', 'size': 11}, {'text': 'dispersion', 'size': 11}, {'text': 'pollutants', 'size': 11}, {'text': 'large', 'size': 10}, {'text': 'post', 'size': 10}, {'text': 'high', 'size': 10}, {'text': 'estimate', 'size': 10}, {'text': 'northbound', 'size': 10}, {'text': 'percentage', 'size': 10}, {'text': 'southbound', 'size': 10}, {'text': 'population', 'size': 10}, {'text': '\\x89\\x88', 'size': 10}, {'text': 'road', 'size': 10}, {'text': 'functions', 'size': 10}, {'text': 'hourly', 'size': 9}, {'text': 'county', 'size': 9}, {'text': 'crashes', 'size': 9}, {'text': 'calpuff', 'size': 9}, {'text': 'paper', 'size': 9}, {'text': 'decreased', 'size': 9}, {'text': 'effects', 'size': 9}, {'text': 'speeds', 'size': 9}, {'text': 'pre', 'size': 9}, {'text': 'involving', 'size': 9}, {'text': 'timing', 'size': 9}, {'text': 'estimation', 'size': 9}, {'text': 'due', 'size': 9}, {'text': 'policies', 'size': 9}, {'text': 'layer', 'size': 9}, {'text': 'scenario', 'size': 9}, {'text': 'risk', 'size': 8}, {'text': 'implemented', 'size': 8}, {'text': 'transportation', 'size': 8}, {'text': 'approach', 'size': 8}, {'text': 'estimated', 'size': 8}, {'text': 'cases', 'size': 8}, {'text': 'hour', 'size': 8}, {'text': 'figure', 'size': 8}, {'text': 'smirnov', 'size': 8}, {'text': 'shows', 'size': 8}, {'text': 'vehicular', 'size': 8}, {'text': 'major', 'size': 8}, {'text': 'local', 'size': 8}, {'text': 'sources', 'size': 8}, {'text': 'kolmogorov', 'size': 8}, {'text': 'duty', 'size': 8}, {'text': 'transmodeler', 'size': 8}, {'text': 'combined', 'size': 8}, {'text': 'shift', 'size': 8}, {'text': 'epa', 'size': 8}, {'text': 'epidemiological', 'size': 8}, {'text': 'models', 'size': 8}, {'text': 'dynamic', 'size': 7}, {'text': 'lee', 'size': 7}, {'text': 'change', 'size': 7}, {'text': '\\x80\\x93', 'size': 7}, {'text': 'unit', 'size': 7}, {'text': 'developed', 'size': 7}, {'text': 'heavy', 'size': 7}, {'text': 'container', 'size': 7}, {'text': 'driving', 'size': 7}, {'text': 'research', 'size': 7}, {'text': 'safety', 'size': 7}, {'text': 'cars', 'size': 7}, {'text': 'traveled', 'size': 7}, {'text': 'system', 'size': 7}, {'text': 'urban', 'size': 7}, {'text': 'arterials', 'size': 7}, {'text': 'mortality', 'size': 7}, {'text': 'pems', 'size': 7}, {'text': 'annual', 'size': 7}, {'text': 'atmospheric', 'size': 7}, {'text': 'baseline', 'size': 7}, {'text': 'giuliano', 'size': 7}, {'text': 'tests', 'size': 7}, {'text': 'o\\xe2', 'size': 7}, {'text': 'provided', 'size': 7}, {'text': 'analyses', 'size': 7}, {'text': 'brien', 'size': 7}, {'text': 'scenarios', 'size': 7}, {'text': 'analyze', 'size': 7}, {'text': 'delivery', 'size': 7}, {'text': 'periods', 'size': 7}, {'text': 'compared', 'size': 7}, {'text': 'caused', 'size': 6}, {'text': 'epa\\xe2', 'size': 6}, {'text': 'logistics', 'size': 6}, {'text': 'cost', 'size': 6}, {'text': 'distributed', 'size': 6}, {'text': 'type', 'size': 6}, {'text': 'work', 'size': 6}, {'text': 'methodology', 'size': 6}, {'text': 'southern', 'size': 6}, {'text': 'caltrans', 'size': 6}, {'text': 'half', 'size': 6}, {'text': 'queues', 'size': 6}, {'text': 'highway', 'size': 6}, {'text': 'arterial', 'size': 6}, {'text': 'note', 'size': 6}, {'text': 'boundary', 'size': 6}, {'text': 'observed', 'size': 6}, {'text': 'assumed', 'size': 6}, {'text': 'case', 'size': 6}, {'text': 'meteorological', 'size': 6}, {'text': 'recent', 'size': 6}, {'text': 'speed', 'size': 6}, {'text': 'asthma', 'size': 6}, {'text': 'noise', 'size': 6}, {'text': 'database', 'size': 6}, {'text': 'aadt', 'size': 6}, {'text': 'od', 'size': 6}, {'text': 'land', 'size': 6}, {'text': 'link', 'size': 6}, {'text': 'similar', 'size': 6}, {'text': 'statistic', 'size': 6}, {'text': 'generated', 'size': 6}, {'text': 'longer', 'size': 6}, {'text': 'daily', 'size': 6}, {'text': 'facilities', 'size': 5}, {'text': 'section', 'size': 5}, {'text': 'operating', 'size': 5}, {'text': 'obtained', 'size': 5}, {'text': 'gate', 'size': 5}, {'text': 'response', 'size': 5}, {'text': 'estimating', 'size': 5}, {'text': 'main', 'size': 5}, {'text': 'versus', 'size': 5}, {'text': 'terminals', 'size': 5}, {'text': 'additional', 'size': 5}, {'text': 'benefits', 'size': 5}, {'text': 'simulated', 'size': 5}, {'text': 'derived', 'size': 5}, {'text': 'excess', 'size': 5}, {'text': 'mid', 'size': 5}, {'text': 'performance', 'size': 5}, {'text': 'implementation', 'size': 5}, {'text': 'terminal', 'size': 5}, {'text': 'activity', 'size': 5}, {'text': 'statistical', 'size': 5}, {'text': 'nearby', 'size': 5}, {'text': 'period', 'size': 5}, {'text': 'shifts', 'size': 5}, {'text': 'higher', 'size': 5}, {'text': 'grid', 'size': 5}, {'text': 'seasonal', 'size': 5}, {'text': 'inventories', 'size': 5}, {'text': 'occurring', 'size': 5}, {'text': 'dollars', 'size': 5}, {'text': 'involvement', 'size': 5}, {'text': 'gis', 'size': 5}, {'text': 'highest', 'size': 5}, {'text': 'valuation', 'size': 5}, {'text': 'trips', 'size': 5}, {'text': 'm', 'size': 5}, {'text': 'volumes', 'size': 5}, {'text': 'represent', 'size': 4}]\n"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Store text and size in lists for making DataFrame\n",
      "text = [word for word, count in fdist.most_common(250)]\n",
      "size = [count for word, count in fdist.most_common(250)]\n",
      "print text[:10]\n",
      "print size[:10]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "['', 'truck', 'traffic', 'pierpass', 'accidents', 'peak', 'pm', 'emissions', 'health', 'data']\n",
        "[2310, 80, 73, 71, 64, 59, 58, 56, 55, 50]\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = pd.DataFrame(text, columns=['text'])\n",
      "data['size'] = size\n",
      "print data.head()\n",
      "data.to_csv('accident_top_250.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "        text  size\n",
        "0             2310\n",
        "1      truck    80\n",
        "2    traffic    73\n",
        "3   pierpass    71\n",
        "4  accidents    64\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Manually remove some words that are not relevant"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}